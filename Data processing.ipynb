{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mystem import mystem as mstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def remove_accents(input_str):\n",
    "    nfс_form = unicodedata.normalize('NFC', input_str)\n",
    "    nfс_form = re.sub(r'[^А-Яа-яЁё\\s\\?\\!-]', u'', nfс_form, flags=re.UNICODE)\n",
    "    return u\"\".join([c for c in nfс_form if not unicodedata.combining(c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Выделение лемм из выхлопа mystem\n",
    "def lemmatized_text_list(contextList):\n",
    "    \"\"\"\n",
    "    Gets lemmas from list of tuples (mystem func)\n",
    "    \"\"\"\n",
    "    line = ''\n",
    "    textList = list()\n",
    "    for sentence in contextList:\n",
    "        if len(sentence) == 0:\n",
    "            continue\n",
    "        for word in sentence:\n",
    "            if word[2] in ['UNKNOWN', 'CONJ', 'INTJ', 'PART', 'PR']:\n",
    "                continue\n",
    "            lemma = word[1]\n",
    "            if lemma != '.':\n",
    "                if len(lemma) > 1 and lemma[-1:] == '?':\n",
    "                    lemma = lemma[:-1]                     \n",
    "                line += lemma + ' '\n",
    "        textList.append(line)\n",
    "        line = ''\n",
    "    return textList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file(path, filename, sentencesList):\n",
    "    outputFile = path + filename\n",
    "    file_obj = open(outputFile, 'w', encoding=\"utf8\")\n",
    "    file_obj.writelines(sentencesList)\n",
    "    file_obj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка НКРЯ (лучшее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainList = ['балка',\n",
    "             'вид',\n",
    "             'винт',\n",
    "             'горн',\n",
    "             'губа',\n",
    "             'жаба',\n",
    "             'клетка',\n",
    "             'крыло',\n",
    "             'купюра', \n",
    "             'курица', \n",
    "             'лавка', \n",
    "             'лайка', \n",
    "             'лев', \n",
    "             'лира', \n",
    "             'мина', \n",
    "             'мишень', \n",
    "             'обед', \n",
    "             'оклад', \n",
    "             'опушка', \n",
    "             'полис', \n",
    "             'пост', \n",
    "             'поток', \n",
    "             'проказа', \n",
    "             'пропасть', \n",
    "             'проспект', \n",
    "             'пытка',\n",
    "             'рысь',\n",
    "             'среда',\n",
    "             'хвост',\n",
    "             'штамп',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачивание xml-файла под каждое слово.\n",
    "\n",
    "Хотел сделать считывание через поток, но там были с этим проблемы, поэтому так."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.parse import quote\n",
    "\n",
    "for word in trainList:\n",
    "    testfile = urllib.request.URLopener()\n",
    "    file_name = 'http://search1.ruscorpora.ru/download-xml.xml?env=alpha&text=lexgramm&mode=main&sort=gr_tagging&lang=ru&nodia=1&parent1=0&level1=0&lex1={}&gramm1=S%2C(nom%7Cgen%7Cgen2%7Cdat%7Cacc%7Cacc2%7Cins%7Cloc%7Cloc2)%2C(sg%7Cpl)%2Cinan&sem-mod1=sem&sem-mod1=sem2&parent2=0&level2=0&min2=1&max2=1&sem-mod2=sem&sem-mod2=sem2&m2=&p=0&dpp=1000&spd=10&spp=1000&out=kwic&dl=xml'.format(quote(word))\n",
    "    try:\n",
    "        testfile.retrieve(file_name, \"Data//НКРЯ//xml//{}.xml\".format(word))\n",
    "    except:\n",
    "        print('Error', word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделение текста из каждого xml.\n",
    "\n",
    "Есть одна проблема. Если брать текст из поля, где содержится текст целиком, то он обрежется, потому что нужное слово выделяется отдельным тегом прямо посреди предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree\n",
    "\n",
    "for word in trainList:\n",
    "    filepath = 'Data//НКРЯ//xml//' + word + '.xml'\n",
    "    e = xml.etree.ElementTree.parse(filepath).getroot()\n",
    "\n",
    "    contextList = list()\n",
    "    tagPrefix = '{urn:schemas-microsoft-com:office:spreadsheet}'\n",
    "\n",
    "    Worksheet = e.find(tagPrefix + 'Worksheet')\n",
    "    Table = Worksheet.find(tagPrefix + 'Table')\n",
    "\n",
    "    count = 0\n",
    "    for child in Table:\n",
    "        if child.tag == tagPrefix + 'Row':\n",
    "            text = ''\n",
    "            cells = child.findall(tagPrefix + 'Cell')\n",
    "            cell = cells[-1]\n",
    "            data = cell.find(tagPrefix + 'Data')\n",
    "            try:\n",
    "                text += data.text\n",
    "            except:\n",
    "                pass\n",
    "            text += word + ' '\n",
    "            cell = cells[5]\n",
    "            data = cell.find(tagPrefix + 'Data')\n",
    "            try:\n",
    "                text += data.text\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if text != 'Full context' + word + ' Right context':\n",
    "                contextList.append(text + '\\n')\n",
    "\n",
    "    write_to_file('Data//НКРЯ//txt//', word + '.txt', contextList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отчистка текстов от лишних символов и обработка mystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mystemDict = dict()\n",
    "\n",
    "for word in trainList:\n",
    "    filename = 'Data//НКРЯ//txt//' + word + '.txt'\n",
    "    file_obj = open(filename, 'r', encoding=\"utf8\")\n",
    "    text = remove_accents(file_obj.read())\n",
    "    mystemDict[word] = mstm(text)\n",
    "    file_obj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка выхлопа mystem (можно было вставить в прошлый цикл)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contextDict = dict()\n",
    "\n",
    "for word in mystemDict:\n",
    "    contextList = mystemDict[word]\n",
    "    \n",
    "    # Выделение лемм\n",
    "    mystemContextList = lemmatized_text_list(contextList)\n",
    "    \n",
    "    # Проверка на наличие слова в тексте (mystem мог поделить контекст на несколько предложений)\n",
    "    mystemContextList = [x + '\\n' for x in mystemContextList if x.find(word) != -1]\n",
    "    \n",
    "    # Удаление предложений, где меньше 3 слов\n",
    "    # Стоит цифра 5, потому что из-за особенности форматирования по краям стоят пустые строки\n",
    "    mystemContextList = [' ' + x for x in mystemContextList if len(x.split(' ')) > 5]\n",
    "    contextDict[word] = mystemContextList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет количества предложений и запись."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077 балка\n",
      "2859 вид\n",
      "1927 винт\n",
      "1637 горн\n",
      "3331 губа\n",
      "1137 жаба\n",
      "3006 клетка\n",
      "2219 крыло\n",
      "1544 купюра\n",
      "1851 курица\n",
      "2154 лавка\n",
      "414 лайка\n",
      "1942 лев\n",
      "1871 лира\n",
      "1807 мина\n",
      "1779 мишень\n",
      "2322 обед\n",
      "1631 оклад\n",
      "2073 опушка\n",
      "701 полис\n",
      "2086 пост\n",
      "1978 поток\n",
      "892 проказа\n",
      "1250 пропасть\n",
      "1698 проспект\n",
      "1861 пытка\n",
      "1977 рысь\n",
      "1899 среда\n",
      "2204 хвост\n",
      "1563 штамп\n"
     ]
    }
   ],
   "source": [
    "for word in trainList:\n",
    "    wordList = contextDict[word]\n",
    "    print(len(wordList), word)\n",
    "    write_to_file('Data//НКРЯ//lemma txt//', word + '.txt', wordList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я считаю, что в данной задаче кроме НКРЯ использовать ничего не нужно, потому что можно сразу получить большой набор предложений с необходимым словом. Код дальше не был использован в итоговой версии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка OpenCorpora (часть кода утеряна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filesList = list()\n",
    "for i in range(2, 4062):\n",
    "    number = str(i)\n",
    "    while len(number) < 4:\n",
    "        number = '0' + number\n",
    "    trainFile = './/Data//OpenCorpora//opencorpora original//' + number +'.txt'\n",
    "    try:\n",
    "        file_obj = open(trainFile, 'r', encoding=\"utf8\")\n",
    "        filesList.append(file_obj.read())\n",
    "        file_obj.close()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# здесь была обработка через mystem и сохранение в отдельный файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textsList = list()\n",
    "for text in filesList:\n",
    "    fileSentencesList = text.split('\\n')\n",
    "    sentencesList = list()\n",
    "    for sentence in fileSentencesList:\n",
    "        tuplesList = sentence.split(' ||| ')\n",
    "        tuplesList = tuplesList[:-1]\n",
    "        sentencesList.append(tuplesList)\n",
    "    textsList.append(sentencesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputFile = 'Data//OpenCorpora//opencorpora lemmas cleaned//text.txt'\n",
    "file_obj = open(outputFile, 'w', encoding=\"utf8\")\n",
    "verbsString = ''\n",
    "for text in textsList:\n",
    "    for sentence in text:\n",
    "        line = ' '\n",
    "        for wordTuple in sentence:\n",
    "            wordInfo = wordTuple[:-1]\n",
    "            wordInfo = wordInfo[1:]\n",
    "            wordInfo = wordInfo.split(' || ')\n",
    "            word = wordInfo[0].split(' ')[0]\n",
    "            mark = wordInfo[1].split(' ')[0]\n",
    "            if mark in ['ADVB', 'ADJF', 'NOUN', 'VERB', 'INFN']:\n",
    "                if mark == 'VERB':\n",
    "                    verbsString = verbsString + word + ' \\n'\n",
    "                line = line + word + ' '\n",
    "        line = line + '\\n'\n",
    "        file_obj.write(line)\n",
    "file_obj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В текстах OpenCorpora у глаголов вместо лемм дают форму ед.ч. им. падежа, поэтому их нужно прогонять в Mystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mystemVerbs = mstm(verbsString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('учу', 'учить', 'V')], [('сохранился', 'сохраняться', 'V')], [('вернулся', 'вернуться', 'V')], [('начинаюсь', 'начинаться', 'V')], [('отличаюсь', 'отличаться', 'V')], [('называюсь', 'называться', 'V')], [('соответствую', 'соответствовать', 'V')], [('выступаю', 'выступать', 'V')], [('есть', 'быть', 'V')], [('прижился', 'приживаться', 'V')]]\n"
     ]
    }
   ],
   "source": [
    "print(mystemVerbs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"8037178b-4f92-4e1f-b274-84d0b6850b00\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"8037178b-4f92-4e1f-b274-84d0b6850b00\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "verbsDict = dict()\n",
    "for sentence in mystemVerbs:\n",
    "    for wordTuple in sentence:\n",
    "        verbsDict[wordTuple[0]] = wordTuple[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'чувствовать'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbsDict['чувствую']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7657"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(verbsDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"af9c42f9-051c-47ee-8577-54cee6c5cb5d\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"af9c42f9-051c-47ee-8577-54cee6c5cb5d\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"END READING\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"12e66f38-261b-44a6-bf40-d3b304746167\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"12e66f38-261b-44a6-bf40-d3b304746167\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"END REPLACING\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"5eb5fe3c-e258-45cf-b8db-05d8cfca3b64\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"5eb5fe3c-e258-45cf-b8db-05d8cfca3b64\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"END WRITING\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputFile = 'Data//OpenCorpora//opencorpora lemmas cleaned//text.txt'\n",
    "file_obj = open(inputFile, 'r', encoding=\"utf8\")\n",
    "text = file_obj.read()\n",
    "file_obj.close()\n",
    "\n",
    "%notify -m \"END READING\"\n",
    "\n",
    "for key in verbsDict.keys():\n",
    "    text = text.replace(' ' + key + ' ', ' ' + verbsDict[key] + ' ')\n",
    "    \n",
    "%notify -m \"END REPLACING\"\n",
    "\n",
    "outputFile = 'Data//OpenCorpora//opencorpora lemmas cleaned//text_modified.txt'\n",
    "file_obj = open(outputFile, 'w', encoding=\"utf8\")\n",
    "file_obj.write(text)\n",
    "file_obj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка ГИКРЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filesList = ['0751_joined_jj.out.gykMSD.txt', \n",
    "             '0752_joined_jj.out.gykMSD.txt', \n",
    "             '0752_joined_jj.out.gykMSD6466.txt',\n",
    "             '0753_joined_jj.out.gykMSD.txt',\n",
    "             '0753_joined_jj.out.gykMSD6936.txt',\n",
    "             '0760_joined_vk.out.gykMSD.txt',\n",
    "             '0760_joined_vk.out.gykMSD6270.txt',\n",
    "             '0761_joined_vk.out.gykMSD.txt',\n",
    "             '0761_joined_vk.out.gykMSD5875.txt',\n",
    "             '0762_joined_vk.out.gykMSD.txt',\n",
    "             '0762_joined_vk.out.gykMSD6173.txt'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_from_file(path, filename):\n",
    "    inputFile = path + filename\n",
    "    file_obj = open(inputFile, 'r', encoding=\"utf8\")\n",
    "    sentencesList = list()\n",
    "    singleSentence = ' '\n",
    "\n",
    "    index = 0\n",
    "    for line in file_obj:\n",
    "        if index < 2:\n",
    "            index += 1\n",
    "            continue\n",
    "    \n",
    "        if line == '\\n':\n",
    "            singleSentence = singleSentence + '\\n'\n",
    "            sentencesList.append(singleSentence)\n",
    "            singleSentence = ' '\n",
    "            continue\n",
    "\n",
    "        wordInfo = line.split('\\t')\n",
    "\n",
    "        if len(wordInfo) < 6:\n",
    "            continue\n",
    "\n",
    "        lemma = wordInfo[3].rstrip()\n",
    "        mark = wordInfo[4][0]\n",
    "        if lemma == '[#UnknownWord]' or mark not in ['N', 'V', 'A', 'R']:\n",
    "            continue\n",
    "        else:\n",
    "            lemma = lemma[:-1]\n",
    "            lemma = lemma[1:]\n",
    "\n",
    "        singleSentence = singleSentence + lemma + ' '\n",
    "    \n",
    "    file_obj.close()\n",
    "    return sentencesList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110288"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentencesListAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for filename in filesList:\n",
    "    sentencesList = read_from_file('Data//ГИКРЯ//GOLD_1.2_release//' , filename)\n",
    "    # удаление предложений с малым количеством слов (с тремя)\n",
    "    sentencesList = [x for x in sentencesList if len(x.split(' ')) > 5]\n",
    "    write_to_file('Data//ГИКРЯ//Lemmatised texts//', filename, sentencesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109922"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentencesListAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentencesListAll = list()\n",
    "for file in filesList:\n",
    "    filename = 'Data//ГИКРЯ//Lemmatised texts//' + file\n",
    "    file_obj = open(filename, 'r', encoding=\"utf8\")\n",
    "    for line in file_obj:\n",
    "        linetext = line.replace('_', ' ').lower()\n",
    "        if linetext not in sentencesListAll:\n",
    "            sentencesListAll.append(linetext)\n",
    "    file_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file('Data//ГИКРЯ//Lemmatised texts//', 'all_texts.txt', sentencesListAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197450\n"
     ]
    }
   ],
   "source": [
    "goldText = 'Data//ГИКРЯ//Lemmatised texts//all_texts.txt'\n",
    "opencorporaText = 'Data//OpenCorpora//opencorpora lemmas cleaned//text_modified_cleaned.txt'\n",
    "\n",
    "sentencesList = list()\n",
    "\n",
    "file_obj = open(opencorporaText, 'r', encoding=\"utf8\")\n",
    "for line in file_obj:\n",
    "    sentencesList.append(line)\n",
    "file_obj.close()\n",
    "\n",
    "file_obj = open(goldText, 'r', encoding=\"utf8\")\n",
    "for line in file_obj:\n",
    "    sentencesList.append(line)\n",
    "file_obj.close()\n",
    "\n",
    "sentencesList = [x for x in sentencesList if len(x.split(' ')) > 5]\n",
    "print(len(sentencesList))\n",
    "write_to_file('Data\\\\', 'corpus.txt', sentencesList)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
