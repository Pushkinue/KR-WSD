{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Частичное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_file(path, word):\n",
    "    \"\"\"Read table with mixed-marked data for Word\"\"\"\n",
    "    \n",
    "    filename = path + word + '.csv'\n",
    "    \n",
    "    dataDf = pd.read_csv(filename, header=None, sep='\\t')\n",
    "    \n",
    "    labeledDf = dataDf[dataDf[1].notnull()]\n",
    "    cols = {labeledDf.columns[0]: \"label\", labeledDf.columns[1]: \"text\"}\n",
    "    labeledDf = labeledDf.rename(columns=cols).reset_index(drop=True)\n",
    "    \n",
    "    nonLabeledDf = dataDf[dataDf[1].isnull()]\n",
    "    cols = {nonLabeledDf.columns[0]: \"text\"}\n",
    "    nonLabeledDf = nonLabeledDf.rename(columns=cols).drop(columns=[1]).reset_index(drop=True)\n",
    "\n",
    "    return labeledDf, nonLabeledDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def learn_clf(model, trainDf):\n",
    "    \"\"\"Modify data to tf-idf and learn a model\"\"\"\n",
    "    \n",
    "    text_clf = Pipeline([('tdidfvect', TfidfVectorizer(ngram_range=(1,2))),\n",
    "                         ('clf', model),\n",
    "                        ])\n",
    "    \n",
    "    text_clf.fit(trainDf.text, trainDf.label)\n",
    "    \n",
    "    return text_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def semi_learn(classesList, predicted_proba, trainDf, testDf):\n",
    "    \"\"\"Expand training data\"\"\"\n",
    "    \n",
    "    startIndex = len(trainDf)\n",
    "    \n",
    "    # Find strong probability and write it down\n",
    "    for index, result in enumerate(predicted_proba):\n",
    "        maximum = max(result)\n",
    "        if maximum >= 0.9:\n",
    "            label = np.argmax(result)\n",
    "            trainDf = trainDf.append({'label': classesList[label], 'text': testDf.iloc[index].text}, \n",
    "                                     ignore_index=True)\n",
    "\n",
    "    endIndex = len(trainDf)\n",
    "    \n",
    "    lenBefore = len(testDf)\n",
    "    \n",
    "    # Remove expanded data from non-labeled data\n",
    "    \n",
    "    testDf = testDf.loc[~testDf['text'].isin(trainDf.text)].reset_index(drop=True)\n",
    "\n",
    "    lenAfter = len(testDf)\n",
    "    \n",
    "    # How many expanded per step\n",
    "    count = lenBefore - lenAfter\n",
    "    \n",
    "    return trainDf, testDf, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "def result_func(dataset, mode, wordList, path, savePath, model, model2):\n",
    "\n",
    "    for word in wordList:\n",
    "        print(word)\n",
    "        bool_break = False\n",
    "\n",
    "        labeledDf, nonLabeledDf = read_file(path, word)\n",
    "        print(word, len(labeledDf), Counter(labeledDf.label))\n",
    "\n",
    "        count = -1\n",
    "        while (count != 0 and len(nonLabeledDf) > 0):\n",
    "            try:\n",
    "                clf = learn_clf(model, labeledDf)\n",
    "                predicted = clf.predict_proba(nonLabeledDf.text)\n",
    "#                 clf2 = learn_clf(model2, labeledDf)\n",
    "#                 predicted2 = clf2.predict_proba(nonLabeledDf.text)\n",
    "                labeledDf, nonLabeledDf, count = semi_learn(clf.classes_, predicted, labeledDf, nonLabeledDf)\n",
    "            except Exception as e:\n",
    "                print('Error', word)\n",
    "\n",
    "                if hasattr(e, 'message'):\n",
    "                    print(e.message)\n",
    "                else:\n",
    "                    print(e)\n",
    "\n",
    "                bool_break = True\n",
    "                break\n",
    "                \n",
    "        if bool_break == False:      \n",
    "            if not os.path.exists(savePath):\n",
    "                os.makedirs(savePath)\n",
    "\n",
    "            outputName = savePath + word + '.csv'\n",
    "            labeledDf.to_csv(outputName, sep='\\t', header=False, index=False)\n",
    "            print('-----')\n",
    "\n",
    "    print('Finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Начало работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'bts-rnc'\n",
    "\n",
    "wordList = ['балка', 'вид', 'винт', 'горн', 'губа', 'жаба', 'клетка',\n",
    "            'крыло', 'купюра', 'курица', 'лавка', 'лайка', 'лев', 'лира',\n",
    "            'мина', 'мишень', 'обед', 'оклад', 'опушка', 'полис', 'пост', \n",
    "            'поток', 'проказа', 'пропасть', 'проспект', 'пытка', 'рысь',\n",
    "            'среда', 'хвост', 'штамп'\n",
    "           ]\n",
    "mode = 'train'\n",
    "\n",
    "# wordList = ['акция', 'баба', 'байка', 'бум', 'бычок', 'вал', 'газ', 'гвоздика',\n",
    "#              'гипербола', 'град', 'гусеница', 'дождь', 'домино', 'забой', 'икра',\n",
    "#              'кабачок', 'капот', 'карьер', 'кличка', 'ключ', 'кок', 'кольцо',\n",
    "#              'концерт', 'котелок', 'крона', 'круп', 'кулак', 'лейка', 'лук',\n",
    "#              'мандарин', 'ножка', 'опора', 'патрон', 'печать', 'пол', 'полоз',\n",
    "#              'почерк', 'пробка', 'рак', 'рок', 'свет', 'секрет', 'скат', 'слог',\n",
    "#              'стан', 'стопка', 'таз', 'такса', 'тюрьма', 'шах', 'шашка'\n",
    "#             ]\n",
    "# mode = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = KNeighborsClassifier(weights='uniform')\n",
    "model2 = MultinomialNB(alpha=2.0, fit_prior=True)\n",
    "\n",
    "model_name_1 = str(model.__class__.__name__)\n",
    "model_name_2 = str(model2.__class__.__name__)\n",
    "\n",
    "inputPath = \"Data/Mixed txt/{}({})/\".format(dataset, mode)\n",
    "savePath = \"Data/Expanded txt/{}({})/{}_{}/\".format(dataset, mode, model_name_1, model_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "балка\n",
      "балка 91 Counter({'34297': 47, '39329': 44})\n",
      "-----\n",
      "вид\n",
      "вид 105 Counter({'18983': 35, '38473': 34, '46934': 21, '16525': 15})\n",
      "-----\n",
      "винт\n",
      "винт 84 Counter({'16398': 32, '17916': 22, '39939': 22, '32507': 8})\n",
      "-----\n",
      "горн\n",
      "горн 100 Counter({'30349': 40, '1': 31, '32374': 24, '0': 5})\n",
      "-----\n",
      "губа\n",
      "губа 73 Counter({'36563': 50, '32217': 17, '40001': 6})\n",
      "-----\n",
      "жаба\n",
      "жаба 94 Counter({'38123': 29, '1': 28, '0': 19, '22390': 18})\n",
      "-----\n",
      "клетка\n",
      "клетка 151 Counter({'16575': 33, '15531': 32, '24810': 29, '19864': 29, '15764': 28})\n",
      "-----\n",
      "крыло\n",
      "крыло 166 Counter({'35257': 37, '31524': 33, '19801': 28, '36977': 24, '20531': 22, '0': 12, '29548': 10})\n",
      "-----\n",
      "купюра\n",
      "купюра 88 Counter({'25844': 54, '12767': 34})\n",
      "-----\n",
      "курица\n",
      "курица 60 Counter({'38375': 33, '33131': 27})\n",
      "-----\n",
      "лавка\n",
      "лавка 52 Counter({'19335': 27, '38881': 25})\n",
      "-----\n",
      "лайка\n",
      "лайка 66 Counter({'21481': 45, '30243': 21})\n",
      "-----\n",
      "лев\n",
      "лев 68 Counter({'28022': 49, '1': 11, '0': 6, '39252': 2})\n",
      "-----\n",
      "лира\n",
      "лира 59 Counter({'34938': 37, '0': 22})\n",
      "-----\n",
      "мина\n",
      "мина 72 Counter({'14200': 45, '23313': 23, '0': 4})\n",
      "-----\n",
      "мишень\n",
      "мишень 78 Counter({'28103': 51, '35543': 27})\n",
      "-----\n",
      "обед\n",
      "обед 116 Counter({'27747': 54, '42118': 28, '20613': 18, '32048': 16})\n",
      "-----\n",
      "оклад\n",
      "оклад 119 Counter({'25098': 71, '29484': 45, '20522': 3})\n",
      "-----\n",
      "опушка\n",
      "опушка 52 Counter({'16750': 29, '40487': 23})\n",
      "-----\n",
      "полис\n",
      "полис 90 Counter({'0': 46, '20510': 44})\n",
      "-----\n",
      "пост\n",
      "пост 104 Counter({'19615': 48, '22320': 23, '21584': 20, '36343': 13})\n",
      "-----\n",
      "поток\n",
      "поток 96 Counter({'41114': 67, '16273': 29})\n",
      "-----\n",
      "проказа\n",
      "проказа 93 Counter({'37005': 52, '24456': 41})\n",
      "-----\n",
      "пропасть\n",
      "пропасть 115 Counter({'39536': 48, '38487': 36, '1': 25, '0': 6})\n",
      "-----\n",
      "проспект\n",
      "проспект 143 Counter({'13284': 77, '1': 27, '28382': 23, '0': 16})\n",
      "-----\n",
      "пытка\n",
      "пытка 91 Counter({'24806': 71, '28262': 20})\n",
      "-----\n",
      "рысь\n",
      "рысь 113 Counter({'36983': 70, '20083': 43})\n",
      "-----\n",
      "среда\n",
      "среда 165 Counter({'27906': 56, '14872': 49, '41363': 37, '37772': 23})\n",
      "-----\n",
      "хвост\n",
      "хвост 128 Counter({'18002': 49, '12982': 31, '40730': 30, '14619': 15, '0': 3})\n",
      "-----\n",
      "штамп\n",
      "штамп 77 Counter({'30859': 30, '34398': 27, '35716': 15, '39926': 5})\n",
      "-----\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "result_func(dataset=dataset, mode=mode, \n",
    "            wordList=wordList, path=inputPath, \n",
    "            savePath=savePath, model=model, \n",
    "            model2=model2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
