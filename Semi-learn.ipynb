{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Частичное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "model = MLPClassifier(solver='lbfgs', alpha=0.001, max_iter=1000, tol=0.001)\n",
    "# svm = LinearSVC()\n",
    "# model = CalibratedClassifierCV(svm, cv=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(path, word):\n",
    "    \n",
    "    trainList = list()\n",
    "    targetList = list()\n",
    "    textList = list()\n",
    "    filename = path + word + '.txt'\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8', newline='') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "        for index, row in enumerate(reader):\n",
    "            if len(row) > 1:\n",
    "                targetList.append(row[0])\n",
    "                trainList.append(row[1])\n",
    "            else:\n",
    "                try:\n",
    "                    textList.append(row[0])\n",
    "                except:\n",
    "                    print('СМОТРИ:', row, index)\n",
    "                    break\n",
    "    return trainList, targetList, textList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def learn_clf(model, trainList, targetList):\n",
    "    \n",
    "    text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', model),\n",
    "                        ])\n",
    "    \n",
    "    text_clf.fit(trainList, targetList)\n",
    "    \n",
    "    return text_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def semi_learn(clf, predicted, trainList, targetList, textList):\n",
    "\n",
    "    startIndex = len(trainList)\n",
    "\n",
    "    for index, result in enumerate(predicted):\n",
    "        maximum = max(result)\n",
    "        if maximum >= 0.9:\n",
    "            label = np.argmax(result)\n",
    "            targetList.append(clf.classes_[label])\n",
    "            trainList.append(textList[index])\n",
    "\n",
    "    endIndex = len(trainList)\n",
    "\n",
    "    lenBefore = len(textList)\n",
    "\n",
    "    for index in range(startIndex, endIndex):\n",
    "        sentence = trainList[index]\n",
    "        if sentence in textList:\n",
    "            textList.remove(sentence)\n",
    "\n",
    "    lenAfter = len(textList)\n",
    "    \n",
    "    count = lenBefore - lenAfter\n",
    "    \n",
    "    return trainList, targetList, textList, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_learn_result(path, word, trainList, targetList):\n",
    "    \n",
    "    outputName = path + word + '.csv'\n",
    "    \n",
    "    with open(outputName, 'w', encoding='utf-8', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "\n",
    "        for index in range(0, len(trainList) - 1):\n",
    "            line = targetList[index] + '\\t' + trainList[index]\n",
    "            wr.writerow([line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordList = [\n",
    "    'балка',\n",
    "    'вид',\n",
    "    'винт',\n",
    "    'горн',\n",
    "    'губа',\n",
    "    'жаба',\n",
    "    'клетка',\n",
    "    'крыло',\n",
    "    'купюра', \n",
    "    'курица',\n",
    "    'лавка', \n",
    "    'лайка', \n",
    "    'лев', \n",
    "    'лира', \n",
    "    'мина', \n",
    "    'мишень',\n",
    "    'обед', \n",
    "    'оклад', \n",
    "    'опушка', \n",
    "    'полис', \n",
    "    'пост', \n",
    "    'поток', \n",
    "    'проказа', \n",
    "    'пропасть', \n",
    "    'проспект', \n",
    "    'пытка',\n",
    "    'рысь',\n",
    "    'среда',\n",
    "    'хвост',\n",
    "    'штамп',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish балка\n",
      "Finish вид\n",
      "Finish винт\n",
      "Finish горн\n",
      "Finish губа\n",
      "Finish жаба\n",
      "СМОТРИ: [] 5\n",
      "Finish клетка\n",
      "Finish крыло\n",
      "Finish купюра\n",
      "Finish курица\n",
      "СМОТРИ: [] 2\n",
      "Finish лавка\n",
      "Finish лайка\n",
      "Finish лев\n",
      "Finish лира\n",
      "Finish мина\n",
      "Finish мишень\n",
      "Finish обед\n",
      "Finish оклад\n",
      "Finish опушка\n",
      "Finish полис\n",
      "Finish пост\n",
      "СМОТРИ: [] 2\n",
      "Finish поток\n",
      "Finish проказа\n",
      "Finish пропасть\n",
      "Finish проспект\n",
      "Finish пытка\n",
      "Finish рысь\n",
      "Finish среда\n",
      "Finish хвост\n",
      "Finish штамп\n"
     ]
    }
   ],
   "source": [
    "path = 'Data/НКРЯ/lemma txt/'\n",
    "\n",
    "for word in wordList:\n",
    "   \n",
    "    bool_break = False\n",
    "    trainList, targetList, textList = read_file(path, word)\n",
    "    count = -1\n",
    "    while (count != 0 and len(textList) > 0):\n",
    "        try:\n",
    "            clf = learn_clf(model, trainList, targetList)\n",
    "            predicted = clf.predict_proba(textList)\n",
    "            trainList, targetList, textList, count = semi_learn(clf, predicted, trainList, targetList, textList)\n",
    "        except:\n",
    "            print('Error', word)\n",
    "            bool_break = True\n",
    "            break\n",
    "            \n",
    "    if bool_break == False:\n",
    "        write_learn_result('Data/НКРЯ/labeled txt/', word, trainList, targetList)\n",
    "        print('Finish', word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
