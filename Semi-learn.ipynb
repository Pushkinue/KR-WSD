{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Частичное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(path, word):\n",
    "    \n",
    "    trainList = list()\n",
    "    targetList = list()\n",
    "    textList = list()\n",
    "    filename = path + word + '.txt'\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8', newline='') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "        for index, row in enumerate(reader):\n",
    "            if len(row) > 1:\n",
    "                targetList.append(row[0])\n",
    "                trainList.append(row[1])\n",
    "            else:\n",
    "                try:\n",
    "                    textList.append(row[0])\n",
    "                except:\n",
    "                    print('СМОТРИ:', row, index)\n",
    "                    pass\n",
    "    return trainList, targetList, textList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def learn_clf(model, trainList, targetList):\n",
    "    \n",
    "    text_clf = Pipeline([('tdidfvect', TfidfVectorizer(ngram_range=(1,2))),\n",
    "                         ('clf', model),\n",
    "                        ])\n",
    "    \n",
    "    text_clf.fit(trainList, targetList)\n",
    "    \n",
    "    return text_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def semi_learn(clf, predicted, trainList, targetList, textList):\n",
    "\n",
    "    startIndex = len(trainList)\n",
    "\n",
    "    for index, result in enumerate(predicted):\n",
    "        maximum = max(result)\n",
    "        if maximum >= 0.9:\n",
    "            label = np.argmax(result)\n",
    "            targetList.append(clf.classes_[label])\n",
    "            trainList.append(textList[index])\n",
    "\n",
    "    endIndex = len(trainList)\n",
    "\n",
    "    lenBefore = len(textList)\n",
    "\n",
    "    for index in range(startIndex, endIndex):\n",
    "        sentence = trainList[index]\n",
    "        if sentence in textList:\n",
    "            textList.remove(sentence)\n",
    "\n",
    "    lenAfter = len(textList)\n",
    "    \n",
    "    count = lenBefore - lenAfter\n",
    "    \n",
    "    return trainList, targetList, textList, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_learn_result(path, word, trainList, targetList):\n",
    "    \n",
    "    outputName = path + word + '.csv'\n",
    "    \n",
    "    with open(outputName, 'w', encoding='utf-8', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "\n",
    "        for index in range(0, len(trainList) - 1):\n",
    "            line = targetList[index] + '\\t' + trainList[index]\n",
    "            wr.writerow([line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "def result_func(dataset, mode, wordList):\n",
    "\n",
    "    path = 'Input\\\\marked txt\\\\' + dataset + '(' + mode + ')/'\n",
    "\n",
    "    for word in wordList:\n",
    "\n",
    "        bool_break = False\n",
    "        trainList, targetList, textList = read_file(path, word)\n",
    "\n",
    "        print(word, Counter(targetList))\n",
    "\n",
    "        count = -1\n",
    "        while (count != 0 and len(textList) > 0):\n",
    "            try:\n",
    "                clf = learn_clf(model, trainList, targetList)\n",
    "                predicted = clf.predict_proba(textList)\n",
    "                trainList, targetList, textList, count = semi_learn(clf, predicted, trainList, targetList, textList)\n",
    "            except Exception as e:\n",
    "                print('Error', word)\n",
    "\n",
    "                if hasattr(e, 'message'):\n",
    "                    print(e.message)\n",
    "                else:\n",
    "                    print(e)\n",
    "\n",
    "                bool_break = True\n",
    "                break\n",
    "\n",
    "        if bool_break == False:\n",
    "\n",
    "            savepath = 'Input\\\\full txt\\\\' + dataset + '(' + mode + ')/' + str(model.__class__.__name__) + '/'        \n",
    "            if not os.path.exists(savepath):\n",
    "                os.makedirs(savepath)\n",
    "\n",
    "            write_learn_result(savepath, word, trainList, targetList)\n",
    "            print('-----')\n",
    "\n",
    "    print('Finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Начало работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordList = [\n",
    "    'балка',\n",
    "    'вид',\n",
    "    'винт',\n",
    "    'горн',\n",
    "    'губа',\n",
    "    'жаба',\n",
    "    'клетка',\n",
    "    'крыло',\n",
    "    'купюра', \n",
    "    'курица',\n",
    "    'лавка', \n",
    "    'лайка', \n",
    "    'лев', \n",
    "    'лира', \n",
    "    'мина', \n",
    "    'мишень',\n",
    "    'обед', \n",
    "    'оклад', \n",
    "    'опушка', \n",
    "    'полис', \n",
    "    'пост', \n",
    "    'поток', \n",
    "    'проказа', \n",
    "    'пропасть', \n",
    "    'проспект', \n",
    "    'пытка',\n",
    "    'рысь',\n",
    "    'среда',\n",
    "    'хвост',\n",
    "    'штамп',\n",
    "]\n",
    "\n",
    "# wordList = [\n",
    "#     'акция',\n",
    "#     'баба',\n",
    "#     'байка',\n",
    "#     'бум',\n",
    "#     'бычок',\n",
    "#     'вал',\n",
    "#     'газ',\n",
    "#     'гвоздика',\n",
    "#     'гипербола', \n",
    "#     'град',\n",
    "#     'гусеница', \n",
    "#     'дождь', \n",
    "#     'домино', \n",
    "#     'забой', \n",
    "#     'икра', \n",
    "#     'кабачок',\n",
    "#     'капот', \n",
    "#     'карьер', \n",
    "#     'кличка', \n",
    "#     'ключ', \n",
    "#     'кок', \n",
    "#     'кольцо', \n",
    "#     'концерт', \n",
    "#     'котелок', \n",
    "#     'крона', \n",
    "#     'круп',\n",
    "#     'кулак',\n",
    "#     'лейка',\n",
    "#     'лук',\n",
    "#     'мандарин',\n",
    "#     'ножка', \n",
    "#     'опора', \n",
    "#     'патрон', \n",
    "#     'печать', \n",
    "#     'пол',\n",
    "#     'полоз', \n",
    "#     'почерк', \n",
    "#     'пробка', \n",
    "#     'рак', \n",
    "#     'рок', \n",
    "#     'свет', \n",
    "#     'секрет', \n",
    "#     'скат', \n",
    "#     'слог', \n",
    "#     'стан',\n",
    "#     'стопка',\n",
    "#     'таз',\n",
    "#     'такса',\n",
    "#     'тюрьма',\n",
    "#     'шах',\n",
    "#     'шашка'\n",
    "# ] \n",
    "\n",
    "dataset = 'bts-rnc'\n",
    "mode = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "балка Counter({'34297': 47, '39329': 44})\n",
      "-----\n",
      "вид Counter({'18983': 35, '38473': 34, '46934': 21, '16525': 15})\n",
      "-----\n",
      "винт Counter({'16398': 32, '17916': 22, '39939': 22, '32507': 8})\n",
      "-----\n",
      "горн Counter({'30349': 40, '1': 31, '32374': 24, '0': 5})\n",
      "-----\n",
      "губа Counter({'36563': 50, '32217': 17, '40001': 6})\n",
      "-----\n",
      "жаба Counter({'38123': 29, '1': 28, '0': 19, '22390': 18})\n",
      "-----\n",
      "клетка Counter({'16575': 33, '15531': 32, '24810': 29, '19864': 29, '15764': 28})\n",
      "-----\n",
      "крыло Counter({'35257': 37, '31524': 33, '19801': 28, '36977': 24, '20531': 22, '0': 12, '29548': 10})\n",
      "-----\n",
      "купюра Counter({'25844': 54, '12767': 34})\n",
      "-----\n",
      "курица Counter({'38375': 33, '33131': 27})\n",
      "-----\n",
      "лавка Counter({'19335': 27, '38881': 25})\n",
      "-----\n",
      "лайка Counter({'21481': 45, '30243': 21})\n",
      "-----\n",
      "лев Counter({'28022': 49, '1': 11, '0': 6, '39252': 2})\n",
      "-----\n",
      "лира Counter({'34938': 37, '0': 21})\n",
      "-----\n",
      "мина Counter({'14200': 45, '23313': 23, '0': 4})\n",
      "-----\n",
      "мишень Counter({'28103': 51, '35543': 27})\n",
      "-----\n",
      "обед Counter({'27747': 54, '42118': 28, '20613': 18, '32048': 16})\n",
      "-----\n",
      "оклад Counter({'25098': 70, '29484': 45, '20522': 3})\n",
      "-----\n",
      "опушка Counter({'16750': 29, '40487': 23})\n",
      "-----\n",
      "полис Counter({'0': 46, '20510': 44})\n",
      "-----\n",
      "пост Counter({'19615': 48, '22320': 23, '21584': 20, '36343': 13})\n",
      "-----\n",
      "поток Counter({'41114': 67, '16273': 29})\n",
      "-----\n",
      "проказа Counter({'37005': 52, '24456': 41})\n",
      "-----\n",
      "пропасть Counter({'39536': 48, '38487': 36, '1': 25, '0': 6})\n",
      "-----\n",
      "проспект Counter({'13284': 77, '1': 27, '28382': 23, '0': 16})\n",
      "-----\n",
      "пытка Counter({'24806': 71, '28262': 20})\n",
      "-----\n",
      "рысь Counter({'36983': 70, '20083': 43})\n",
      "-----\n",
      "среда Counter({'27906': 56, '14872': 49, '41363': 37, '37772': 23})\n",
      "-----\n",
      "хвост Counter({'18002': 49, '12982': 31, '40730': 30, '14619': 15, '0': 3})\n",
      "-----\n",
      "штамп Counter({'30859': 30, '34398': 27, '35716': 15, '39926': 5})\n",
      "-----\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# model = MultinomialNB(alpha=2.0, fit_prior=True)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(weights='uniform')\n",
    "\n",
    "# from sklearn.naive_bayes import BernoulliNB\n",
    "# model = BernoulliNB()\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# model = GradientBoostingClassifier()\n",
    "\n",
    "result_func(dataset=dataset, mode=mode, wordList=wordList)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
