{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Частичное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(path, word):\n",
    "    \n",
    "    trainList = list()\n",
    "    targetList = list()\n",
    "    textList = list()\n",
    "    filename = path + word + '.txt'\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8', newline='') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "        for index, row in enumerate(reader):\n",
    "            if len(row) > 1:\n",
    "                targetList.append(row[0])\n",
    "                trainList.append(row[1])\n",
    "            else:\n",
    "                try:\n",
    "                    textList.append(row[0])\n",
    "                except:\n",
    "                    print('СМОТРИ:', row, index)\n",
    "                    pass\n",
    "    return trainList, targetList, textList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def learn_clf(model, trainList, targetList):\n",
    "    \n",
    "    text_clf = Pipeline([('tdidfvect', TfidfVectorizer(ngram_range=(1,2))),\n",
    "                         ('clf', model),\n",
    "                        ])\n",
    "    \n",
    "    text_clf.fit(trainList, targetList)\n",
    "    \n",
    "    return text_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def semi_learn(clf, predicted, trainList, targetList, textList):\n",
    "\n",
    "    startIndex = len(trainList)\n",
    "\n",
    "    for index, result in enumerate(predicted):\n",
    "        maximum = max(result)\n",
    "        if maximum >= 0.9:\n",
    "            label = np.argmax(result)\n",
    "            targetList.append(clf.classes_[label])\n",
    "            trainList.append(textList[index])\n",
    "\n",
    "    endIndex = len(trainList)\n",
    "\n",
    "    lenBefore = len(textList)\n",
    "\n",
    "    for index in range(startIndex, endIndex):\n",
    "        sentence = trainList[index]\n",
    "        if sentence in textList:\n",
    "            textList.remove(sentence)\n",
    "\n",
    "    lenAfter = len(textList)\n",
    "    \n",
    "    count = lenBefore - lenAfter\n",
    "    \n",
    "    return trainList, targetList, textList, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_learn_result(path, word, trainList, targetList):\n",
    "    \n",
    "    outputName = path + word + '.csv'\n",
    "    \n",
    "    with open(outputName, 'w', encoding='utf-8', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "\n",
    "        for index in range(0, len(trainList) - 1):\n",
    "            line = targetList[index] + '\\t' + trainList[index]\n",
    "            wr.writerow([line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "def result_func(dataset, mode, wordList):\n",
    "\n",
    "    path = 'Input\\\\marked txt\\\\' + dataset + '(' + mode + ')\\\\'\n",
    "\n",
    "    for word in wordList:\n",
    "\n",
    "        bool_break = False\n",
    "        trainList, targetList, textList = read_file(path, word)\n",
    "\n",
    "        print(word, len(targetList), Counter(targetList))\n",
    "\n",
    "        count = -1\n",
    "        while (count != 0 and len(textList) > 0):\n",
    "            try:\n",
    "                clf = learn_clf(model, trainList, targetList)\n",
    "                predicted = clf.predict_proba(textList)\n",
    "                trainList, targetList, textList, count = semi_learn(clf, predicted, trainList, targetList, textList)\n",
    "            except Exception as e:\n",
    "                print('Error', word)\n",
    "\n",
    "                if hasattr(e, 'message'):\n",
    "                    print(e.message)\n",
    "                else:\n",
    "                    print(e)\n",
    "\n",
    "                bool_break = True\n",
    "                break\n",
    "\n",
    "        if bool_break == False:\n",
    "\n",
    "            savepath = 'Input\\\\full txt\\\\' + dataset + '(' + mode + ')\\\\' + str(model.__class__.__name__) + '\\\\'        \n",
    "            if not os.path.exists(savepath):\n",
    "                os.makedirs(savepath)\n",
    "\n",
    "            write_learn_result(savepath, word, trainList, targetList)\n",
    "            print('-----')\n",
    "\n",
    "    print('Finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Начало работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wordList = [\n",
    "#     'балка',\n",
    "#     'вид',\n",
    "#     'винт',\n",
    "#     'горн',\n",
    "#     'губа',\n",
    "#     'жаба',\n",
    "#     'клетка',\n",
    "#     'крыло',\n",
    "#     'купюра', \n",
    "#     'курица',\n",
    "#     'лавка', \n",
    "#     'лайка', \n",
    "#     'лев', \n",
    "#     'лира', \n",
    "#     'мина', \n",
    "#     'мишень',\n",
    "#     'обед', \n",
    "#     'оклад', \n",
    "#     'опушка', \n",
    "#     'полис', \n",
    "#     'пост', \n",
    "#     'поток', \n",
    "#     'проказа', \n",
    "#     'пропасть', \n",
    "#     'проспект', \n",
    "#     'пытка',\n",
    "#     'рысь',\n",
    "#     'среда',\n",
    "#     'хвост',\n",
    "#     'штамп',\n",
    "# ]\n",
    "\n",
    "wordList = [\n",
    "    'акция',\n",
    "    'баба',\n",
    "    'байка',\n",
    "    'бум',\n",
    "    'бычок',\n",
    "    'вал',\n",
    "    'газ',\n",
    "    'гвоздика',\n",
    "    'гипербола', \n",
    "    'град',\n",
    "    'гусеница', \n",
    "    'дождь', \n",
    "    'домино', \n",
    "    'забой', \n",
    "    'икра', \n",
    "    'кабачок',\n",
    "    'капот', \n",
    "    'карьер', \n",
    "    'кличка', \n",
    "    'ключ', \n",
    "    'кок', \n",
    "    'кольцо', \n",
    "    'концерт', \n",
    "    'котелок', \n",
    "    'крона', \n",
    "    'круп',\n",
    "    'кулак',\n",
    "    'лейка',\n",
    "    'лук',\n",
    "    'мандарин',\n",
    "    'ножка', \n",
    "    'опора', \n",
    "    'патрон', \n",
    "    'печать', \n",
    "    'пол',\n",
    "    'полоз', \n",
    "    'почерк', \n",
    "    'пробка', \n",
    "    'рак', \n",
    "    'рок', \n",
    "    'свет', \n",
    "    'секрет', \n",
    "    'скат', \n",
    "    'слог', \n",
    "    'стан',\n",
    "    'стопка',\n",
    "    'таз',\n",
    "    'такса',\n",
    "    'тюрьма',\n",
    "    'шах',\n",
    "    'шашка'\n",
    "] \n",
    "\n",
    "dataset = 'bts-rnc'\n",
    "mode = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "акция 134 Counter({'29853': 69, '28176': 38, '15738': 27})\n",
      "-----\n",
      "баба 111 Counter({'29090': 42, '38405': 24, '21130': 23, '1': 13, '0': 9})\n",
      "-----\n",
      "байка 79 Counter({'16141': 75, '39858': 4})\n",
      "-----\n",
      "бум 56 Counter({'41843': 33, '32940': 19, '18362': 4})\n",
      "-----\n",
      "бычок 66 Counter({'27009': 34, '0': 28, '26270': 4})\n",
      "-----\n",
      "вал 109 Counter({'33648': 34, '0': 27, '41024': 25, '1': 23})\n",
      "-----\n",
      "газ 61 Counter({'23414': 28, '17569': 21, '16756': 12})\n",
      "-----\n",
      "гвоздика 75 Counter({'31219': 35, '0': 22, '26662': 18})\n",
      "-----\n",
      "гипербола 38 Counter({'1': 24, '0': 14})\n",
      "-----\n",
      "град 82 Counter({'13861': 30, '29527': 21, '0': 16, '35134': 15})\n",
      "-----\n",
      "гусеница 43 Counter({'19345': 24, '21860': 19})\n",
      "-----\n",
      "дождь 56 Counter({'40011': 35, '22422': 21})\n",
      "-----\n",
      "домино 91 Counter({'38622': 37, '13675': 30, '1': 24})\n",
      "-----\n",
      "забой 44 Counter({'36412': 29, '15050': 15})\n",
      "-----\n",
      "икра 74 Counter({'19490': 27, '28149': 24, '15898': 23})\n",
      "-----\n",
      "кабачок 60 Counter({'0': 30, '37286': 30})\n",
      "-----\n",
      "капот 64 Counter({'15899': 35, '13120': 29})\n",
      "-----\n",
      "карьер 18 Counter({'30451': 18})\n",
      "-----\n",
      "кличка 64 Counter({'31031': 43, '19182': 21})\n",
      "-----\n",
      "ключ 91 Counter({'17836': 32, '20503': 28, '27790': 20, '14507': 10, '35285': 1})\n",
      "-----\n",
      "кок 62 Counter({'0': 31, '2': 27, '1': 4})\n",
      "-----\n",
      "кольцо 106 Counter({'40335': 33, '13963': 24, '28664': 22, '20733': 15, '13759': 12})\n",
      "-----\n",
      "концерт 38 Counter({'36483': 37, '31612': 1})\n",
      "-----\n",
      "котелок 105 Counter({'33576': 57, '12686': 48})\n",
      "-----\n",
      "крона 105 Counter({'28683': 66, '37840': 39})\n",
      "-----\n",
      "круп 78 Counter({'2': 36, '0': 22, '1': 20})\n",
      "-----\n",
      "кулак 77 Counter({'24978': 39, '39305': 38})\n",
      "-----\n",
      "лейка 44 Counter({'19118': 25, '0': 19})\n",
      "-----\n",
      "лук 78 Counter({'30469': 46, '12915': 32})\n",
      "-----\n",
      "мандарин 93 Counter({'32076': 52, '0': 41})\n",
      "-----\n",
      "ножка 128 Counter({'29948': 54, '26020': 38, '21161': 30, '35159': 6})\n",
      "-----\n",
      "опора 59 Counter({'19525': 33, '31474': 26})\n",
      "-----\n",
      "патрон 79 Counter({'20891': 35, '31259': 33, '0': 11})\n",
      "-----\n",
      "печать 88 Counter({'20336': 47, '34398': 22, '24513': 19})\n",
      "-----\n",
      "пол 79 Counter({'27405': 43, '31775': 22, '30412': 14})\n",
      "-----\n",
      "полоз 43 Counter({'38992': 33, '41697': 7, '0': 3})\n",
      "-----\n",
      "почерк 83 Counter({'35099': 47, '14920': 36})\n",
      "-----\n",
      "пробка 135 Counter({'13108': 68, '34835': 54, '18558': 7, '30391': 6})\n",
      "-----\n",
      "рак 129 Counter({'13493': 49, '26528': 44, '30960': 36})\n",
      "-----\n",
      "рок 86 Counter({'14466': 47, '40621': 39})\n",
      "-----\n",
      "свет 238 Counter({'37357': 102, '20888': 71, '20737': 55, '24170': 10})\n",
      "-----\n",
      "секрет 55 Counter({'19939': 48, '28164': 7})\n",
      "-----\n",
      "скат 68 Counter({'23838': 32, '13130': 27, '1': 7, '0': 2})\n",
      "-----\n",
      "слог 56 Counter({'15152': 35, '21947': 21})\n",
      "-----\n",
      "стан 75 Counter({'0': 37, '40379': 25, '13900': 12, '1': 1})\n",
      "-----\n",
      "стопка 93 Counter({'25286': 69, '26126': 24})\n",
      "-----\n",
      "таз 66 Counter({'30033': 40, '14586': 26})\n",
      "-----\n",
      "такса 67 Counter({'35039': 39, '36673': 28})\n",
      "-----\n",
      "тюрьма 19 Counter({'14853': 19})\n",
      "-----\n",
      "шах 187 Counter({'28796': 96, '13377': 91})\n",
      "-----\n",
      "шашка 208 Counter({'29740': 89, '37239': 70, '23002': 49})\n",
      "-----\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# model = MultinomialNB(alpha=2.0, fit_prior=True)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(weights='uniform')\n",
    "\n",
    "# from sklearn.naive_bayes import BernoulliNB\n",
    "# model = BernoulliNB()\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# model = GradientBoostingClassifier()\n",
    "\n",
    "result_func(dataset=dataset, mode=mode, wordList=wordList)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
